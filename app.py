# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14MS-S2NhJ6G7tdhKxiKVFPyT0nHkzths
"""

#!pip install gradio
#!pip install yt-dlp

#!pip install vosk pydub

#!wget https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip
#!unzip vosk-model-small-en-us-0.15.zip

import gradio as gr
import yt_dlp as youtube_dl
import os
import wave
import json
from vosk import Model, KaldiRecognizer
from pydub import AudioSegment
import re
from transformers import pipeline
import requests
import zipfile

# Specify the model name directly
model_name = "distilbert-base-uncased-finetuned-sst-2-english"
sentiment_analysis = pipeline("sentiment-analysis", model=model_name)

# Function to download and extract the Vosk model
def download_vosk_model():
    model_url = "https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip"
    model_dir = "vosk-model-small-en-us-0.15"
    if not os.path.exists(model_dir):
        print("Downloading Vosk model...")
        response = requests.get(model_url, stream=True)
        with open("vosk-model-small-en-us-0.15.zip", "wb") as f:
            for chunk in response.iter_content(chunk_size=1024):
                if chunk:
                    f.write(chunk)
        print("Extracting Vosk model...")
        with zipfile.ZipFile("vosk-model-small-en-us-0.15.zip", 'r') as zip_ref:
            zip_ref.extractall(".")
        os.remove("vosk-model-small-en-us-0.15.zip")
    else:
        print("Vosk model already exists.")

# Define functions
def download_video(url):
    ydl_opts = {
        'format': 'bestaudio/best',
        'outtmpl': 'downloaded_video.%(ext)s',
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'wav',
            'preferredquality': '192',
        }],
    }

    with youtube_dl.YoutubeDL(ydl_opts) as ydl:
        ydl.download([url])

    return 'downloaded_video.wav'

def transcribe_audio(audio_path):
    # Download and load Vosk model
    download_vosk_model()

    # Convert audio to a format supported by Vosk
    audio = AudioSegment.from_wav(audio_path)
    audio.export("converted_audio.wav", format="wav")

    model_dir = os.path.abspath("vosk-model-small-en-us-0.15")
    model = Model(model_dir)
    wf = wave.open("converted_audio.wav", "rb")
    rec = KaldiRecognizer(model, wf.getframerate())

    transcription = []

    while True:
        data = wf.readframes(4000)
        if len(data) == 0:
            break
        if rec.AcceptWaveform(data):
            result = rec.Result()
            text = json.loads(result).get('text', '')
            transcription.append(text)

    transcription.append(json.loads(rec.FinalResult()).get('text', ''))
    wf.close()

    return ' '.join(transcription)

def preprocess_text(text):
    # Remove non-alphabetic characters and convert to lower case
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    text = text.lower()
    return text

def analyze_sentiment(text):
    result = sentiment_analysis(text)
    return result[0]

def process_youtube_video(url):
    audio_path = download_video(url)
    transcription = transcribe_audio(audio_path)
    cleaned_text = preprocess_text(transcription)
    sentiment_result = analyze_sentiment(cleaned_text)

    # Return sentiment label and score
    sentiment_label = sentiment_result['label'].lower()
    sentiment_score = sentiment_result['score']

    return f"The sentiment of the video is: {sentiment_label} with a score of {sentiment_score:.2f}"

# Create Gradio interface
def gradio_interface(url):
    return process_youtube_video(url)

iface = gr.Interface(
    fn=gradio_interface,
    inputs=gr.Textbox(label="YouTube Video URL", placeholder="Paste YouTube URL here"),
    outputs=gr.Textbox(label="Sentiment Analysis Result"),
    title="YouTube Video Sentiment Analysis",
    description="Paste a YouTube video URL to analyze its sentiment. The pipeline will download the video, transcribe the audio, and analyze the sentiment of the transcript."
)

# Launch the interface
if __name__ == "__main__":
    iface.launch()